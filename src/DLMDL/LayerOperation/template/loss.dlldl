@name: loss

@caffe_import:
    import sys
    from caffe import layers as L

@tf_import:
    import tensorflow as tf

@attributes:
[

]

@caffe_compile_time:
    logits = self.get_input('logits')
    labels = self.get_input('labels')
    layer = L.SoftmaxWithLoss(logits, labels, name=self.name)
    # self.set_output('output', layer)
    for output_name in self.outputs_list:
        self.set_output(output_name, layer)

@caffe_run_time:
    pass

@tf_compile_time:
    pass

@tf_run_time:
    def apiConstructor(logits, labels):
        softmax_cross_entropy_with_logits = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,
                                                                                           labels=labels,
                                                                                           name=None)
        loss_ = tf.reduce_mean(softmax_cross_entropy_with_logits)
        tf.summary.scalar('loss', loss_)
        self.set_output('output', loss_)

    logits = self.get_input('logits')
    labels = tf.cast(self.get_input('labels'), tf.int64)
    logits_indim = self.get_dimension('logits')
    labels_indim = self.get_dimension('labels')

    with tf.name_scope(self.name) as scope:
        if learning_option.get("parallel", None) != "DP":
             with tf.device('/job:worker/task:%s' % self.get_attr('device')):
                apiConstructor(logits, labels)
        else:
            apiConstructor(logits, labels)
