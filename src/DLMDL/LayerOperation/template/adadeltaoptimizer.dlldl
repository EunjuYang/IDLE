@name: adadeltaoptimizer

@caffe_import:


@tf_import:
    import tensorflow as tf

@attributes:
[
    {
        "default": 0.95, 
        "source": "opt", 
        "mandatory": "both", 
        "name": "rho"
    },
    {
        "default": 1e-05,
        "source": "opt", 
        "mandatory": "both", 
        "name": "epsilon"
    }
]

@caffe_compile_time:
    learning_rate = learning_option.get("learning_rate")
    rho = learning_option.get("rho", self.rho)
    epsilon = learning_option.get("epsilon", self.epsilon)


    for key in ['learning_rate', 'rho', 'epsilon']:
        try:
            del learning_option[key]
        except KeyError:
            pass
    learning_option['base_lr'] = float(learning_rate)
    learning_option['momentum'] = float(rho)
    learning_option['delta'] = float(epsilon)
    learning_option['type'] = 'AdaDelta'

@caffe_run_time:
    pass

@tf_compile_time:
    pass

@tf_run_time:
    def apiConstructor(input_, learning_rate, rho, epsilon):
        global_step = tf.train.get_or_create_global_step()
        adadeltaopt = tf.train.AdadeltaOptimizer(learning_rate=learning_rate, rho=rho, epsilon=epsilon)
        adadeltaopt_ = adadeltaopt.minimize(input_, colocate_gradients_with_ops=True, global_step=global_step)
        self.set_output('output', adadeltaopt_)
        self.set_output('global_step', global_step)

    learning_rate = learning_option.get("learning_rate")
    rho = learning_option.get("rho", self.rho)
    epsilon = learning_option.get("epsilon", self.epsilon)
    input_ = self.get_input('loss')

    with tf.name_scope(self.name) as scope:
        if learning_option.get("parallel", None) != "DP":
            with tf.device('/job:worker/task:%s' % self.get_attr('device')):
                apiConstructor(input_, learning_rate, rho, epsilon)
        else:
            apiConstructor(input_, learning_rate, rho, epsilon)